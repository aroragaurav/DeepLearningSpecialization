{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa2a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8.3.2 in /Users/leonidas/Desktop/m/ml/github/workspaces/learning/ml/pytorch/dlwpt_code/dlwpt_venv/lib/python3.10/site-packages (from imageio) (11.0.0)\n",
      "Requirement already satisfied: numpy in /Users/leonidas/Desktop/m/ml/github/workspaces/learning/ml/pytorch/dlwpt_code/dlwpt_venv/lib/python3.10/site-packages (from imageio) (2.2.1)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.36.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc27986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/b837ndks0hd_73hq93kslgpc0000gp/T/ipykernel_13180/3731146654.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread('../data/p1ch4/image-dog/bobby.jpg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "img_arr = imageio.imread('../data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "925815f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 1280, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "img = torch.from_numpy(img_arr)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81f00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 720, 1280])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img.permute(2,0,1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c533d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 256, 256]), torch.uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
    "batch.shape, batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96611bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat1.png', 'cat2.png', 'cat3.png']\n",
      "torch.Size([3, 256, 256])\n",
      "torch.Size([3, 256, 256])\n",
      "torch.Size([3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/b837ndks0hd_73hq93kslgpc0000gp/T/ipykernel_13180/2469954926.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 256, 256]), torch.float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "data_dir = '../data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "            if os.path.splitext(name)[-1] == '.png']\n",
    "print(filenames)\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    #print(img_t.shape)\n",
    "    img_t = img_t.permute(2,0,1)\n",
    "    #print(img_t.shape)\n",
    "    img_t = img_t[:3]\n",
    "    print(img_t.shape)\n",
    "    batch[i] = img_t\n",
    "    \n",
    "batch.shape, batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92c631b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize value by divinding by max\n",
    "batch = batch.float()\n",
    "batch.dtype\n",
    "batch = batch/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74e04c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 256, 256]), torch.float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize value by subtracting mean and divei by std dev\n",
    "t = batch[:,0]\n",
    "print(t.shape)\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:,c])\n",
    "    std = torch.std(batch[:,c])\n",
    "    batch[:,c] = (batch[:,c]-mean)/std\n",
    "batch.shape, batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e02df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 99/99  (100.0%)\n"
     ]
    }
   ],
   "source": [
    "#vloume data of ct scan\n",
    "dir_path = '../data/p1ch4/volumetric-dicom/2-LUNG 3.0  B70f-04083'\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2827442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = torch.from_numpy(vol_arr)\n",
    "print(vol.shape)\n",
    "vol = torch.unsqueeze(vol, 0)\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6797d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]],\n",
       "      shape=(4898, 12), dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tabular format data\n",
    "import csv\n",
    "import numpy as np\n",
    "wine_path = \"../data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wine_arr = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
    "wine_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "392e5278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=\";\"))\n",
    "wine_arr.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d5375b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wine_arr)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9dcb174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "845d6f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8add6dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 6, 6,  ..., 6, 7, 6]), torch.int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = target.long()\n",
    "target, target.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53e1f6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 10])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot vector for the targets\n",
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b01c562c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot.scatter_( 1, target.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80737223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize the dataset\n",
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d4aa7831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4a0ccc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0392e-01, -8.1117e-01,  1.7622e+00,  ..., -8.2569e+00,\n",
       "         -3.0593e+00, -1.1320e+00],\n",
       "        [-7.7907e-01,  2.1417e+00,  3.9660e-01,  ...,  4.9003e+00,\n",
       "          1.1761e-02, -6.6974e-01],\n",
       "        [ 1.7486e+00,  1.7313e-01,  4.4933e+00,  ...,  3.1460e+00,\n",
       "         -3.8271e+00, -2.7355e-01],\n",
       "        ...,\n",
       "        [-4.9822e-01, -3.7641e+00, -9.8453e+00,  ..., -8.6954e+00,\n",
       "         -2.2916e+00, -7.3577e-01],\n",
       "        [-1.9025e+00,  1.1574e+00, -2.3346e+00,  ...,  6.6546e+00,\n",
       "         -8.4337e+00,  1.5093e+00],\n",
       "        [-1.2004e+00, -6.7169e+00,  3.1278e+00,  ...,  3.1460e+00,\n",
       "         -1.3040e+01,  8.4899e-01]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean)/ data_var\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73dcbb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual analysis to find the quality\n",
    "bad_indexes = target <=3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea0d82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select bad data by using advanced indexing\n",
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c393f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[target <=3]\n",
    "mid_data = data[(target>3) & (target <7)]\n",
    "good_data = data[target>=7]\n",
    "bad_mean = torch.mean(bad_data, 0)\n",
    "mid_mean = torch.mean(mid_data, 0)\n",
    "good_mean = torch.mean(good_data, 0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5124ab25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulphur_dioxide = 141.83\n",
    "total_sulfur_data = data[:, 6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulphur_dioxide)\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "341623fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target>5\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2eae362f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "n_matches, n_matches/n_predicted, n_matches/n_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf7b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "bikes_numpy = np.loadtxt(\"../data/p1ch4/bike-sharing-dataset/hour-fixed.csv\",\n",
    "                         dtype=np.float32,\n",
    "                         delimiter=\",\",\n",
    "                         skiprows=1,\n",
    "                         converters={1: lambda x: float(x[8:10])})\n",
    "bikes_numpy[51:55]\n",
    "col_list = next(csv.reader(open(\"../data/p1ch4/bike-sharing-dataset/hour-fixed.csv\"), delimiter=\",\"))\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d46816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56da3971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05b75832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24 ,bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "997ddb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape for N * C * L ordering\n",
    "#option 1\n",
    "daily_bikes = daily_bikes.permute(0, 2, 1)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14c073ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#option2 \n",
    "daily_bikes = bikes.view(-1, 24 ,bikes.shape[1])\n",
    "daily_bikes = daily_bikes.transpose(1,2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b8f7a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 17])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode the columns into categorical encoding \n",
    "#weather data to start with\n",
    "first_day = bikes[:24].long()\n",
    "first_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24202c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(first_day[:,9].unsqueeze(1).shape)\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "weather_onehot.scatter_(dim=1, index=first_day[:,9].unsqueeze(1) -1, value=1.0)\n",
    "weather_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e1b844b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c779484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1) [:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98121cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "           0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "          16.0000]]),\n",
       " tensor([[1., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes[:1], weather_onehot[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4927a47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf770c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(dim=1, index= daily_bikes[:,9,:].long().unsqueeze(1) -1, value=1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ab62777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 21, 24])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), 1)\n",
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a9f5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp we can scale\n",
    "temp = daily_bikes[:,10,:]\n",
    "temp_min = torch.min(temp)\n",
    "temp_max = torch.max(temp)\n",
    "\n",
    "daily_bikes [:, 10, :] = (daily_bikes [:, 10, :] - temp_min)/ (temp_max - temp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdd82803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other way via mean and std dev\n",
    "temp = daily_bikes[:,10,:]\n",
    "temp_mean = torch.mean(temp)\n",
    "temp_std = torch.var(temp)\n",
    "daily_bikes [:, 10, :] = (daily_bikes [:, 10, :] - temp_mean)/ temp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08bb5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# textembeddings\n",
    "with open('../data/p1ch4/jane-austen/1342-0.txt', encoding='utf8') as f:\n",
    "    text =f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44ac95dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text.split('\\n')\n",
    "line = lines[200]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a506a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([70, 128]), torch.float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#char embeddings one hot\n",
    "letter_t = torch.zeros(len(line), 128)\n",
    "letter_t.shape, letter_t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b3e9114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    #print(letter_index)\n",
    "    letter_t[i][letter_index] = 1.0\n",
    "letter_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30fd0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73765165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embeddings \n",
    "def clean_words(input_str):\n",
    "    punctuations='.,;:\"!“?_-'\n",
    "    word_list = input_str.lower().replace('\\n', ' ').split()\n",
    "    word_list = [word.strip(punctuations) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9238ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
       " ['impossible',\n",
       "  'mr',\n",
       "  'bennet',\n",
       "  'impossible',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'acquainted',\n",
       "  'with',\n",
       "  'him'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "379a28df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8267, 3848)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = sorted(set(clean_words(text)))\n",
    "words2indexdict = {word:i for (i, word) in enumerate(words_list)}\n",
    "len(words2indexdict), words2indexdict['impossible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19ae121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 3848 impossible\n",
      " 1 4928 mr\n",
      " 2  899 bennet\n",
      " 3 3848 impossible\n",
      " 4 8049 when\n",
      " 5 3759 i\n",
      " 6  449 am\n",
      " 7 5081 not\n",
      " 8  249 acquainted\n",
      " 9 8126 with\n",
      "10 3637 him\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 8267])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tensor\n",
    "word_t = torch.zeros(len(words_in_line), len(words2indexdict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    wordindex = words2indexdict[word]\n",
    "    word_t[i][wordindex] =1.0\n",
    "    print('{:2} {:4} {}'.format(i, wordindex, word))\n",
    "    \n",
    "word_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "970e23ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124592, 8267])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_t = torch.zeros(len(clean_words(text)), len(words2indexdict))\n",
    "for i, word in enumerate(clean_words(text)):\n",
    "    wordindex = words2indexdict[word]\n",
    "    word_t[i][wordindex] =1.0\n",
    "    #print('{:2} {:4} {}'.format(i, wordindex, word))\n",
    "    \n",
    "word_t.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f5778cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33e57fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(word_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ad7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dlwpt_venv",
   "language": "python",
   "name": "dlwpt_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
